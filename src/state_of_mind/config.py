"""
ğŸŒŠ å¿ƒå¢ƒé…ç½®ä¸­æ¢
"""
import importlib.metadata
import os
import threading
from pathlib import Path
from typing import Dict, Any
from src.state_of_mind.utils.constants import (
    ROOT_DIR,
    STORAGE_LOCAL,
    LOG_KEEP_DAYS, LOG_MAX_BYTES, LOG_BACKUP_COUNT,
    PATH_FILE_PYPROJECT,
    PATH_FILE_CHAINA_IP_LIST, PATH_FILE_PROMPTS,
    PATH_FILE_DEFAULT_TEMPLATE, STORAGE_REDIS, ModelName, PATH_FILE_APP_JSON,
)
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

from src.state_of_mind.utils.file_util import FileUtil
from src.state_of_mind.utils.logger import LoggerManager, _logger_dict

try:
    import tomli as tomllib  # Python < 3.11
except ImportError:
    import tomllib  # Python 3.11+


class Config:
    CHINESE_NAME = "å¿ƒå¢ƒé…ç½®ä¸­æ¢"

    __slots__ = [
        'ROOT_DIR', 'OUTPUT_ROOT', 'VERSION', 'LLM_RECOMMENDED_PARAMS',
        'DATA_YUAN_RAW_DIR', 'DATA_YUAN_DYE_VAT_DIR', 'REPORTS_DIR',
        'LOGS_DIR', 'LOGS_FALLBACK_DIR', 'PATH_FILE_APP_JSON', 'REPORT_TITLE',
        'STATIC_PROMPTS_DIR', 'STATIC_REPORTS_DIR', 'SUGGESTION_TYPE',
        'FILE_PROMPTS_PATH', 'FILE_CHAINA_IP_LIST_PATH', 'FILE_DEFAULT_TEMPLATE_PATH',
        'STORAGE_BACKEND', 'STORAGE_LOCAL', 'STORAGE_REDIS', 'MEDIUM_PARALLEL_CONCURRENCY',
        'REDIS_HOST', 'REDIS_PORT', 'REDIS_DB', 'REDIS_PASSWORD', 'REDIS_TIMEOUT',
        'LLM_BACKEND', 'LLM_MODEL', 'LLM_API_URL', 'LLM_API_KEY', 'CURRENT_PARALLEL_CONCURRENCY',
        'LOG_KEEP_DAYS', 'LOG_MAX_BYTES', 'LOG_BACKUP_COUNT', 'LOG_ENABLE_INSPECT',
        'MAX_PARALLEL_CONCURRENCY', 'LLM_CACHE_MAX_SIZE', 'LLM_CACHE_TTL',
        '_observer', '_watcher_thread', '_stop_event', 'logger', 'metadata', '__setitem__',
    ]

    def __init__(self):
        self.ROOT_DIR = ROOT_DIR
        self._observer = None
        self._watcher_thread = None
        self._stop_event = threading.Event()
        self.metadata = self._load_metadata()
        self.VERSION = self.metadata.get("version", "dev-local")

        self.logger = LoggerManager  # ä½¿ç”¨ç±»æ¥å£
        self.logger.info("ğŸŒŠ æ­£åœ¨åŠ è½½å¿ƒæµ·é…ç½®...")
        self._load()
        self.start_watcher()

        # æ³¨å…¥é…ç½®
        self.logger.inject_config(self)
        self.logger.initialize(configured=True)
        self.logger.info("ğŸŒŠ å¿ƒé•œé…ç½®åŠ è½½å®Œæˆ")

    def _load_metadata(self) -> Dict[str, Any]:
        # å…³å¿ƒçš„ URL é”®ï¼ˆç”¨äºæ ‡å‡†åŒ–è¾“å‡ºï¼‰
        STANDARD_URL_KEYS = ("Homepage", "Repository", "Documentation")

        # é»˜è®¤ fallback å€¼
        metadata = {
            "name": "psytext-analyst",
            "version": "dev-local",
            "description": "å¿ƒé•œæ–‡æœ¬åˆ†æç³»ç»Ÿ",
            "authors": [],
            "license": "",
            "urls": {key: "" for key in STANDARD_URL_KEYS}
        }

        # ğŸ” ç¬¬ä¸€æ­¥ï¼šå°è¯•é€šè¿‡ importlib.metadata è¯»å–å·²å®‰è£…åŒ…çš„å…ƒæ•°æ®
        try:
            normalized_name = "psytext-analyst"
            pkg_metadata = importlib.metadata.metadata(normalized_name)

            metadata["name"] = pkg_metadata.get("Name", metadata["name"])
            metadata["version"] = pkg_metadata.get("Version", metadata["version"])
            metadata["description"] = pkg_metadata.get("Summary", metadata["description"])
            metadata["license"] = pkg_metadata.get("License", metadata["license"])

            # å¤„ç†ä½œè€…ï¼šæ”¯æŒ Author + Author-email
            authors = []
            author = pkg_metadata.get("Author")
            author_email = pkg_metadata.get("Author-email")
            if author:
                authors.append({"name": author.strip(), "email": (author_email or "").strip()})
            metadata["authors"] = authors

            # è§£æ Project-URLsï¼ˆæ ¼å¼: "Label, URL"ï¼‰
            raw_urls = {}
            for item in pkg_metadata.get_all("Project-URL", []):
                label, sep, url = item.partition(",")
                if sep:  # ç¡®ä¿æœ‰é€—å·åˆ†éš”
                    raw_urls[label.strip()] = url.strip()
                else:
                    # å…¼å®¹å¼‚å¸¸æ ¼å¼ï¼Œè·³è¿‡æˆ–è®°å½•è­¦å‘Šï¼ˆå¯é€‰ï¼‰
                    self.logger.debug(f"è·³è¿‡æ— æ•ˆ Project-URL æ ¼å¼: {item}")

            # Home-page æ˜¯å•ç‹¬å­—æ®µï¼ˆæ—§å¼ï¼‰
            if "Home-page" in pkg_metadata:
                raw_urls.setdefault("Homepage", pkg_metadata["Home-page"])

            # æ ‡å‡†åŒ– urlsï¼šåªä¿ç•™å…³å¿ƒçš„é”®ï¼Œä½†å…è®¸æ‰©å±•ï¼ˆå¯é€‰ï¼‰
            metadata["urls"] = {
                key: raw_urls.get(key, "") for key in STANDARD_URL_KEYS
            }

        except importlib.metadata.PackageNotFoundError:
            pass  # åŒ…æœªå®‰è£…ï¼Œç»§ç»­ä» pyproject.toml è¯»
        except Exception as e:
            self.logger.warning(f"è¯»å–å·²å®‰è£…åŒ…å…ƒæ•°æ®å¤±è´¥: {e}")

        # ğŸ” ç¬¬äºŒæ­¥ï¼šå›é€€åˆ°è¯»å–æœ¬åœ° pyproject.toml
        pyproject_path = PATH_FILE_PYPROJECT
        if not pyproject_path.exists():
            self.logger.warning(f"âš ï¸ pyproject.toml ä¸å­˜åœ¨: {pyproject_path}")
            return metadata

        try:
            with open(pyproject_path, "rb") as f:
                data = tomllib.load(f)

            proj = data.get("project", {})

            # è¦†ç›–åŸºç¡€å­—æ®µ
            metadata["name"] = proj.get("name", metadata["name"])
            metadata["version"] = proj.get("version", metadata["version"])
            metadata["description"] = proj.get("description", metadata["description"])

            # Licenseï¼ˆPEP 621 æ”¯æŒ str æˆ– {text: "..."}ï¼‰
            license_info = proj.get("license")
            if isinstance(license_info, dict):
                metadata["license"] = license_info.get("text", "")
            elif isinstance(license_info, str):
                metadata["license"] = license_info

            # Authorsï¼ˆä¼˜å…ˆ authorsï¼Œå…¶æ¬¡ maintainersï¼‰
            def _parse_persons(persons):
                result = []
                for p in persons or []:
                    if isinstance(p, dict):
                        name = p.get("name", "").strip()
                        email = p.get("email", "").strip()
                        if name:
                            result.append({"name": name, "email": email})
                return result

            authors = _parse_persons(proj.get("authors"))
            if not authors:
                authors = _parse_persons(proj.get("maintainers"))
            metadata["authors"] = authors

            # URLsï¼šä» TOML ç›´æ¥è¯»å–
            toml_urls = proj.get("urls", {})
            metadata["urls"] = {
                key: toml_urls.get(key, "") for key in STANDARD_URL_KEYS
            }

            return metadata

        except Exception as e:
            self.logger.exception(f"[CRITICAL] è¯»å– pyproject.toml å¤±è´¥: {e}")
            return metadata

    def _load(self):
        # === Step 1: ä» app.json è¯»å–é…ç½® ===
        self.PATH_FILE_APP_JSON = PATH_FILE_APP_JSON
        raw_config = FileUtil().read_json_file(PATH_FILE_APP_JSON)

        # === Step 2: å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼šä¼˜å…ˆä»ç¯å¢ƒå˜é‡å–ï¼Œå…¶æ¬¡ä» raw_configï¼Œæœ€åç”¨é»˜è®¤å€¼ ===
        def get_config(key: str, default, cast):
            env_key = key
            if env_key in os.environ:
                val = os.environ[env_key]
                if cast == int:
                    return int(val)
                elif cast == bool:
                    return val.lower() in ("true", "1", "yes", "on")
                return val
            return raw_config.get(key, default)

        self.OUTPUT_ROOT = Path("/home/psytext_analyst/data")
        # self.OUTPUT_ROOT = Path(DEFAULT_OUTPUT_ROOT) # æœ¬åœ°æµ‹è¯•ä½¿ç”¨

        # === Step 3: æ„å»ºåŠ¨æ€è·¯å¾„ ===
        self._setup_paths()

        # === Step 4: å­˜å‚¨é…ç½® ===
        self.STORAGE_LOCAL = STORAGE_LOCAL
        self.STORAGE_REDIS = STORAGE_REDIS
        self.STORAGE_BACKEND = get_config("XINJING_STORAGE_BACKEND", STORAGE_LOCAL, cast=str)
        self.LLM_CACHE_MAX_SIZE = get_config("XINJING_LLM_CACHE_MAX_SIZE", 4096, cast=int)
        self.LLM_CACHE_TTL = get_config("XINJING_LLM_CACHE_TTL", 3600, cast=int)
        self.REDIS_HOST = get_config("XINJING_REDIS_HOST", "redis", cast=str)
        self.REDIS_PORT = get_config("XINJING_REDIS_PORT", 6379, cast=int)
        self.REDIS_DB = get_config("XINJING_REDIS_DB", 0, cast=int)
        self.REDIS_PASSWORD = get_config("XINJING_REDIS_PASSWORD", None, cast=str)  # æ³¨æ„ï¼šç¯å¢ƒå˜é‡ä¸­ null è¦ä¼ ç©ºå­—ç¬¦ä¸²
        self.REDIS_TIMEOUT = get_config("XINJING_REDIS_TIMEOUT", 5, cast=int)

        # === Step 5: LLM é…ç½® ===
        self.LLM_BACKEND = str(raw_config.get("XINJING_LLM_BACKEND")).lower()
        self.LLM_MODEL = str(raw_config.get("XINJING_LLM_MODEL")).lower()
        self.LLM_API_URL = raw_config.get("XINJING_LLM_API_URL")
        self.LLM_API_KEY = raw_config.get("XINJING_LLM_API_KEY")
        self.SUGGESTION_TYPE = raw_config.get("XINJING_SUGGESTION_TYPE")
        self.LLM_RECOMMENDED_PARAMS = raw_config.get("XINJING_LLM_RECOMMENDED_PARAMS")

        self.REPORT_TITLE = get_config("XINJING_REPORT_TITLE", "æ–‡æœ¬å¤šæ¨¡æ€æ„ŸçŸ¥åˆ†ææŠ¥å‘Š", cast=str)

        # è®¾ç½®é»˜è®¤å€¼ï¼ˆä»…å½“ç»Ÿä¸€å­—æ®µæœªæä¾›æ—¶ï¼‰
        if self.LLM_BACKEND == ModelName.QWEN:
            if not self.LLM_MODEL:
                self.LLM_MODEL = ModelName.QWEN3_MAX
            if not self.LLM_API_URL:
                self.LLM_API_URL = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
        elif self.LLM_BACKEND == ModelName.DEEPSEEK:
            if not self.LLM_MODEL:
                self.LLM_MODEL = ModelName.DEEPSEEK_CHAT
            if not self.LLM_API_URL:
                self.LLM_API_URL = "https://api.deepseek.com"

        # === Step 6: æ—¥å¿—é…ç½®ï¼ˆè¿™äº›æ˜¯å¸¸é‡ï¼Œä¸åŠ¨ï¼‰===
        self.LOG_KEEP_DAYS = int(raw_config.get("XINJING_LOG_KEEP_DAYS")) or int(LOG_KEEP_DAYS)
        self.LOG_MAX_BYTES = int(raw_config.get("XINJING_LOG_MAX_BYTES")) or int(LOG_MAX_BYTES)
        self.LOG_BACKUP_COUNT = int(raw_config.get("XINJING_LOG_BACKUP_COUNT")) or int(LOG_BACKUP_COUNT)

        # === Step 7: å¹¶å‘ ===
        self.MAX_PARALLEL_CONCURRENCY = int(raw_config.get("XINJING_MAX_PARALLEL_CONCURRENCY", 10))
        self.CURRENT_PARALLEL_CONCURRENCY = int(raw_config.get("XINJING_CURRENT_PARALLEL_CONCURRENCY", 3))
        self.MEDIUM_PARALLEL_CONCURRENCY = int(raw_config.get("XINJING_MEDIUM_PARALLEL_CONCURRENCY", 5))

    def _setup_paths(self):
        """åŸºäº OUTPUT_ROOT åŠ¨æ€æ„å»ºæ‰€æœ‰è¾“å‡ºè·¯å¾„"""
        # è¾“å‡ºç›®å½•
        self.DATA_YUAN_RAW_DIR = self.OUTPUT_ROOT / "raw"
        self.DATA_YUAN_DYE_VAT_DIR = self.OUTPUT_ROOT / "dye_vat"
        self.REPORTS_DIR = self.OUTPUT_ROOT / "reports"
        self.LOGS_DIR = self.OUTPUT_ROOT / "logs"
        self.LOGS_FALLBACK_DIR = self.OUTPUT_ROOT / "logs_fallback"

        for d in [self.DATA_YUAN_RAW_DIR, self.DATA_YUAN_DYE_VAT_DIR, self.REPORTS_DIR, self.LOGS_DIR,
                  self.LOGS_FALLBACK_DIR]:
            d.mkdir(parents=True, exist_ok=True)

        self.FILE_PROMPTS_PATH = PATH_FILE_PROMPTS
        self.FILE_CHAINA_IP_LIST_PATH = PATH_FILE_CHAINA_IP_LIST
        self.FILE_DEFAULT_TEMPLATE_PATH = PATH_FILE_DEFAULT_TEMPLATE

    def _parse_bool(self, val: str) -> bool:
        return val.strip().lower() in ("true", "1", "yes", "on")

    def get(self, key: str, default=None):
        return getattr(self, key.upper(), default)

    def as_dict(self):
        return {k: getattr(self, k) for k in self.__slots__ if not k.startswith("_") and hasattr(self, k)}

    def reload(self):
        old_config = self.as_dict()
        self._load()
        new_config = self.as_dict()
        self.logger.info("ğŸ”„ å¿ƒé•œé…ç½®å·²çƒ­é‡è½½")

        # è®¡ç®—å˜æ›´é¡¹
        diff_keys = {k for k in old_config if old_config[k] != new_config[k]}
        if diff_keys:
            self.logger.info("ğŸ”§ é…ç½®å˜æ›´é¡¹: %s", sorted(diff_keys))

        # === 1. å¤„ç†æ—¥å¿—ç³»ç»Ÿé‡å»º ===
        LOG_KEYS = {"LOG_KEEP_DAYS", "LOG_MAX_BYTES", "LOG_BACKUP_COUNT"}
        if diff_keys & LOG_KEYS:
            self.logger.clear_cache()
            for logger_obj in _logger_dict.values():
                if hasattr(logger_obj, "_handlers_added"):
                    logger_obj._needs_reconfigure = True

        # === 2. å¤„ç† LLM å¼•æ“ç¼“å­˜æ¸…ç†ï¼ˆç²¾å‡†åˆ¤æ–­ï¼‰===
        LLM_SENSITIVE_KEYS = {
            "LLM_BACKEND",
            "LLM_MODEL",
            "LLM_API_KEY",
            "LLM_API_URL",
            "LLM_RECOMMENDED_PARAMS"
        }

        if diff_keys & LLM_SENSITIVE_KEYS:
            self.logger.info("ğŸ”‘ æ£€æµ‹åˆ° LLM æ•æ„Ÿé…ç½®å˜æ›´ï¼Œè§¦å‘ç¼“å­˜æ¸…ç†...")
            try:
                from src.state_of_mind.utils.registry import GlobalSingletonRegistry
                GlobalSingletonRegistry.clear_llm_caches()
            except Exception as e:
                self.logger.exception(f"âŒ æ¸…ç† LLM ç¼“å­˜å¤±è´¥: {e}")

    # ==================== æ–‡ä»¶ç›‘å¬ ====================

    def _start_observer(self):
        observer = Observer()
        event_handler = self._create_event_handler()
        observer.schedule(event_handler, str(self.ROOT_DIR), recursive=False)
        observer.start()
        self._observer = observer

        try:
            while not self._stop_event.wait(1):
                pass
        except Exception as e:
            self.logger.exception(f"ğŸ›‘ ç›‘å¬å™¨å¼‚å¸¸: {e}")
        finally:
            observer.stop()
            observer.join()
            self.logger.info("ğŸ›‘ ç›‘å¬å™¨å·²åœæ­¢")

    def _create_event_handler(self):
        config = self

        class EnvFileHandler(FileSystemEventHandler):
            def on_modified(self, event):
                if event.is_directory:
                    return
                p = Path(event.src_path)
                if p.name in PATH_FILE_APP_JSON.resolve():
                    config.logger.info(f"ğŸ“ æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å˜æ›´: {p.name}ï¼Œè§¦å‘çƒ­é‡è½½...")
                    config.reload()

        return EnvFileHandler()

    def start_watcher(self):
        if self._watcher_thread and self._watcher_thread.is_alive():
            self.logger.warning("ğŸ‘€ ç›‘å¬å™¨å·²åœ¨è¿è¡Œä¸­...")
            return
        self._stop_event.clear()
        self._watcher_thread = threading.Thread(target=self._start_observer, daemon=True)
        self._watcher_thread.start()
        self.logger.info("ğŸ‘€ å·²å¯åŠ¨é…ç½®æ–‡ä»¶ç›‘å¬å™¨ï¼ˆè‡ªåŠ¨çƒ­é‡è½½ï¼‰")

    def stop_watcher(self):
        if self._stop_event.is_set():
            self.logger.info("ğŸ›‘ ç›‘å¬å™¨æœªè¿è¡Œï¼Œæ— éœ€åœæ­¢")
            return
        self._stop_event.set()
        if self._observer:
            self._observer.stop()
        self.logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢ç›‘å¬å™¨...")
        if self._watcher_thread:
            self._watcher_thread.join(timeout=3)
            if self._watcher_thread.is_alive():
                self.logger.warning("âš ï¸ ç›‘å¬çº¿ç¨‹æœªèƒ½åŠæ—¶é€€å‡º")
            else:
                self.logger.info("âœ… ç›‘å¬å™¨å·²å®‰å…¨åœæ­¢")


# ğŸŒŠ å…¨å±€é…ç½®å®ä¾‹
config = Config()
