from __future__ import annotations
from typing import Type, Dict, ClassVar
import hashlib
import json
import asyncio
from src.state_of_mind.llm.base import LLMBackend
from src.state_of_mind.utils.logger import LoggerManager as logger


class GlobalSingletonRegistry:
    """
    å…¨å±€æ³¨å†Œä¸­å¿ƒ
    - æ³¨å†Œ LLM åç«¯ç±»ï¼ˆå¦‚ qwenã€deepseekï¼‰
    - æŒ‰è¿æ¥å‚æ•°ç¼“å­˜ LLMBackend å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ + å¼‚æ­¥åˆå§‹åŒ–ï¼‰
    - æ”¯æŒè¿è¡Œæ—¶æ¸…é™¤ç¼“å­˜ä»¥å®ç°é…ç½®çƒ­é‡è½½
    """
    CHINESE_NAME = "å…¨å±€æ³¨å†Œä¸­å¿ƒ"

    _backends: Dict[str, Type[LLMBackend]] = {}
    _backend_instances: Dict[str, LLMBackend] = {}  # backend å®ä¾‹ç¼“å­˜
    # ä½¿ç”¨ asyncio.Lockï¼Œä½†æ³¨æ„ï¼šä¸èƒ½åœ¨ç±»å®šä¹‰æ—¶ç›´æ¥å®ä¾‹åŒ–ï¼ˆéœ€å»¶è¿Ÿï¼‰
    _lock: ClassVar[asyncio.Lock] = None

    @classmethod
    def _get_lock(cls) -> asyncio.Lock:
        if cls._lock is None:
            cls._lock = asyncio.Lock()
        return cls._lock

    @classmethod
    def register_backend(cls, name: str, backend_class: Type[LLMBackend]):
        """æ³¨å†Œ LLM åç«¯ç±»"""
        if not issubclass(backend_class, LLMBackend):
            raise TypeError(f"Backend must inherit from LLMBackend, got {backend_class}")
        cls._backends[name] = backend_class
        logger.info("âœ… æ³¨å†Œ LLM åç«¯: %s", name)

    @classmethod
    def _make_backend_key(cls, name: str, llm_config: dict) -> str:
        """
        åŸºäº backend åç§°å’Œè¿æ¥çº§é…ç½®ç”Ÿæˆå”¯ä¸€ key
        """
        key_data = {
            "backend": name,
            "api_key_hash": hashlib.md5(llm_config["api_key"].encode()).hexdigest()[:8],
            "timeout": llm_config["timeout"]
        }
        # å¯é€‰å­—æ®µï¼šåªæœ‰å½“ backend å®é™…ä½¿ç”¨æ—¶æ‰åŠ å…¥
        backend_class = cls._backends[name]
        if getattr(backend_class, '_uses_api_url', True):  # é»˜è®¤ True
            key_data["api_url"] = llm_config.get("api_url", "")
        config_str = json.dumps(key_data, sort_keys=True, default=str, ensure_ascii=False)
        return hashlib.md5(config_str.encode("utf-8")).hexdigest()

    @classmethod
    async def get_backend_async(cls, name: str) -> LLMBackend:
        if name not in cls._backends:
            raise ValueError(f"æœªçŸ¥çš„ LLM åç«¯: {name}")

        # === ç»Ÿä¸€é…ç½®åˆå¹¶é€»è¾‘ ===
        llm_config = cls._resolve_backend_configs()
        key = cls._make_backend_key(name, llm_config)

        lock = cls._get_lock()
        async with lock:
            if key not in cls._backend_instances:
                logger.info(f"ğŸ†• åˆ›å»º {name} LLMBackend å®ä¾‹ï¼ˆé…ç½®å˜æ›´ï¼‰")
                try:
                    instance = cls._backends[name]()
                    await instance.init(llm_config)
                    cls._backend_instances[key] = instance
                except Exception as e:
                    logger.error(f"âŒ åˆå§‹åŒ– {name} backend å¤±è´¥: {e}")
                    raise
            return cls._backend_instances[key]

    @classmethod
    def _resolve_backend_configs(cls) -> dict:
        from src.state_of_mind.config import config
        llm_config = {
            "api_key": config.LLM_API_KEY,
            "timeout": config.get("LLM_API_TIMEOUT", 120),
            "api_url": config.LLM_API_URL
        }
        return llm_config

    @classmethod
    async def async_clear_llm_caches(cls):
        async with cls._get_lock():
            for instance in cls._backend_instances.values():
                if hasattr(instance, 'close') and callable(instance.close):
                    try:
                        instance.close()
                    except Exception as e:
                        logger.warning(f"âš ï¸ å…³é—­ backend å®ä¾‹æ—¶å‡ºé”™: {e}")
            cls._backend_instances.clear()
            logger.info("ğŸ§¹ å·²æ¸…é™¤æ‰€æœ‰ LLM backend ç¼“å­˜å®ä¾‹")
