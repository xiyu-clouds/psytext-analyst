import json
import time
from typing import Dict, Any, Optional
from abc import ABC, abstractmethod
from src.state_of_mind.common.llm_response import LLMResponse
from src.state_of_mind.stages.perception.data_validator import DataValidator
from src.state_of_mind.utils.async_decorators import async_timed
from src.state_of_mind.utils.llm_helpers import remove_check, extract_json_safely
from src.state_of_mind.utils.logger import LoggerManager as logger
import httpx
from src.state_of_mind.utils.retry_util import retry_decorator


class LLMBackend(ABC):
    """
    æŠ½è±¡åŸºç±»ï¼šæ‰€æœ‰ LLM åç«¯å¿…é¡»ç»§æ‰¿
    """
    CHINESE_NAME = "æŠ½è±¡åŸºç±»LLMåç«¯"

    def __init__(self):
        self.client: Optional[httpx.AsyncClient] = None
        self.api_url: Optional[str] = None
        self._initialized = False
        self.data_validator = DataValidator()

    async def init(self, configs: Dict[str, Any]) -> 'LLMBackend':
        if self._initialized:
            return self

        api_key = configs.get("api_key")
        if not api_key:
            raise ValueError(f"{self.CHINESE_NAME} ç¼ºå°‘ api_key é…ç½®")

        timeout = int(configs.get("timeout", 60.0))
        self.api_url = self._build_api_url(configs)
        self.client = httpx.AsyncClient(
            headers=self._build_headers(api_key),
            timeout=timeout
        )
        self._initialized = True
        logger.info(f"âœ… {self.CHINESE_NAME} åˆå§‹åŒ–å®Œæˆ" + (f"ï¼ŒAPI URL: {self.api_url}" if self.api_url else ""))
        return self

    @abstractmethod
    def _build_api_url(self, configs: Dict[str, Any]) -> str:
        """å­ç±»æä¾› API åœ°å€æ„å»ºé€»è¾‘"""
        pass

    def _build_headers(self, api_key: str) -> dict:
        """é»˜è®¤ headerï¼Œå­ç±»å¯ override"""
        return {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

    @abstractmethod
    def _build_json_payload(
            self,
            prompt: str,
            model: str,
            params: dict,
            *,
            system_prompt: Optional[str] = None,
            **kwargs
    ) -> Dict[str, Any]:
        """
        å­ç±»å®ç°ï¼šæ„å»ºç¬¦åˆè¯¥ LLM åè®®çš„è¯·æ±‚ä½“
        """
        pass

    @abstractmethod
    def _build_text_payload(
            self,
            prompt: str,
            model: str,
            params: dict,
            **kwargs
    ) -> Dict[str, Any]:
        """
        å­ç±»å®ç°ï¼šæ„å»ºç¬¦åˆè¯¥ LLM åè®®çš„è¯·æ±‚ä½“
        """
        pass

    @abstractmethod
    def _extract_content_from_response(self, data: Dict) -> Optional[str]:
        pass

    # ========================
    # ç»Ÿä¸€è°ƒç”¨å…¥å£ï¼ˆæ¨¡æ¿æ–¹æ³•ï¼‰
    # ========================
    @async_timed
    @retry_decorator(max_retries=3, enable_exp_backoff=True)
    async def async_call(
            self,
            prompt: str,
            model: str,
            params: dict,
            template_name: str,
            step_name: str,
            prompt_type: str
    ) -> Dict[str, Any]:
        """
        ç»Ÿä¸€å…¥å£ï¼šè°ƒç”¨ LLM å¹¶è¿”å›æ ‡å‡†åŒ– LLMResponse ç»“æ„ã€‚
        å­ç±»æ— éœ€é‡å†™æ­¤æ–¹æ³•ï¼Œåªéœ€å®ç°æŠ½è±¡æ–¹æ³•ã€‚
        """
        start_time = time.time()
        latency_ms: Optional[float] = None
        system_prompt = "ä½ å¿…é¡»è¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON å¯¹è±¡ã€‚ä¸è¦æœ‰ä»»ä½•é¢å¤–æ–‡å­—è§£é‡Šã€å‰ç¼€ã€åç¼€æˆ– Markdown ä»£ç å—ã€‚ç¡®ä¿è¾“å‡ºæ˜¯æœ‰æ•ˆçš„ json æ ¼å¼ã€‚"

        try:
            payload = self._build_json_payload(
                prompt=prompt,
                model=model,
                params=params,
                system_prompt=system_prompt
            )

            logger.info(f"[{self.CHINESE_NAME} - åŸå§‹æ•°æ®å¤„ç†] è°ƒç”¨ LLM å¼‚æ­¥ API", extra={
                "model": model,
                "template_name": template_name,
                "step_name": step_name,
                "prompt_length": len(prompt)
            })

            assert self.client is not None and self.api_url is not None, "æœªåˆå§‹åŒ– client æˆ– api_url"
            response = await self.client.post(self.api_url, json=payload)
            latency_ms = (time.time() - start_time) * 1000

            # è®°å½•åŸå§‹å“åº”ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            try:
                resp_debug = response.json()
            except Exception:
                resp_debug = response.text[:200]
            logger.info(f"[{self.CHINESE_NAME} - åŸå§‹æ•°æ®å¤„ç†] åŸå§‹å“åº”: {resp_debug}")

            # --- å¤„ç†é 200 å“åº” ---
            if response.status_code != 200:
                error_msg = self._parse_api_error(response)

                if response.status_code >= 500 or response.status_code == 429:
                    # è§¦å‘é‡è¯•ï¼ˆç”± retry_decorator æ•è·ï¼‰
                    fake_request = httpx.Request(method="POST", url=self.api_url)
                    raise httpx.HTTPStatusError(
                        message=error_msg,
                        request=fake_request,
                        response=response
                    )
                else:
                    # å®¢æˆ·ç«¯é”™è¯¯ï¼ˆ400/401/403/404ï¼‰ï¼šä¸é‡è¯•ï¼Œè¿”å› API é”™è¯¯
                    logger.warning(
                        f"[{self.CHINESE_NAME} - åŸå§‹æ•°æ®å¤„ç†] API è¿”å›å®¢æˆ·ç«¯é”™è¯¯",
                        extra={
                            "status_code": response.status_code,
                            "error": error_msg,
                            "template_name": template_name,
                            "step_name": step_name
                        }
                    )
                    return LLMResponse.from_api_error(
                        status_code=response.status_code,
                        error_message=error_msg,
                        model=model,
                        template_name=template_name,
                        step_name=step_name,
                        prompt_type=prompt_type,
                        latency_ms=latency_ms
                    ).to_dict()

            # --- å¤„ç† 200 å“åº” ---
            content = self._extract_content_from_response(response.json())
            if not content or not content.strip():
                api_error = "æ¨¡å‹è¿”å›å†…å®¹ä¸ºç©º"
                logger.warning("æ¨¡å‹è¿”å›ç©ºå†…å®¹", extra={
                    "template_name": template_name,
                    "step_name": step_name
                })
                validation_result = {"is_valid": False, "cleaned_data": {}, "errors": [api_error]}
                raw_content = None
            else:
                content = remove_check(content.strip())
                raw_content = content
                parsed_json = extract_json_safely(content)
                validation_result = self.data_validator.validate(
                    data=parsed_json,
                    template_name=template_name,
                    step_name=step_name
                )
            # æ„é€ æˆåŠŸè°ƒç”¨çš„å“åº”ï¼ˆæ— è®ºç»“æ„æ˜¯å¦æœ‰æ•ˆï¼‰
            return LLMResponse.from_successful_call(
                valid_structure=validation_result["is_valid"],
                data=validation_result["cleaned_data"] or {},
                raw_response=raw_content,
                validation_errors=validation_result["errors"],
                api_error="æ¨¡å‹è¿”å›å†…å®¹ä¸ºç©º" if not raw_content else None,
                model=model,
                template_name=template_name,
                step_name=step_name,
                prompt_type=prompt_type,
                latency_ms=latency_ms
            ).to_dict()
        except Exception as e:
            # ç³»ç»Ÿçº§å¼‚å¸¸ï¼šç½‘ç»œã€è¶…æ—¶ã€JSON è§£æå´©æºƒç­‰
            system_error = str(e)
            logger.exception(
                f"[{self.CHINESE_NAME} - åŸå§‹æ•°æ®å¤„ç†] async_call ç³»ç»Ÿçº§å¼‚å¸¸",
                extra={
                    "model": model,
                    "template_name": template_name,
                    "step_name": step_name,
                    "error": system_error
                }
            )
            return LLMResponse.from_system_error(
                system_error=system_error,
                model=model,
                template_name=template_name,
                step_name=step_name,
                prompt_type=prompt_type,
                include_traceback=True
            ).to_dict()

    @async_timed
    @retry_decorator(max_retries=3, enable_exp_backoff=True)
    async def generate_text(
            self,
            prompt: str,
            model: str,
            params: dict
    ) -> str:
        """æ³¨æ„ï¼šæ­¤æ–¹æ³•ä¿æŒè¿”å› strï¼Œä¸èµ° LLMResponseï¼ˆå› ç”¨é€”ä¸åŒï¼‰"""
        start_time = time.time()
        try:
            payload = self._build_text_payload(
                prompt=prompt,
                model=model,
                params=params,
            )

            log_params = {k: v for k, v in params.items() if k in ("temperature", "max_tokens", "top_p")}
            logger.info(
                f"ğŸ“ [{self.CHINESE_NAME} - ç”Ÿæˆå»ºè®®] è°ƒç”¨ LLM API",
                extra={
                    "model": model,
                    "params": log_params,
                    "prompt_length": len(prompt),
                    "prompt_preview": prompt[:100].replace("\n", "\\n")
                }
            )

            response = await self.client.post(self.api_url, json=payload)
            latency_ms = (time.time() - start_time) * 1000

            if response.status_code != 200:
                err = f"HTTP {response.status_code}: {response.text[:200]}"
                logger.error(f"âŒ [{self.CHINESE_NAME}] generate_text å¤±è´¥", extra={"error": err})
                return f"ç”Ÿæˆå¤±è´¥: {err}"

            content = self._extract_content_from_response(response.json())
            if not content:
                logger.warning(f"âš ï¸ [{self.CHINESE_NAME}] è¿”å›ç©ºå†…å®¹")
                return "ç”Ÿæˆå¤±è´¥ï¼šæ— å†…å®¹è¿”å›"

            stripped = content.strip()
            logger.info(
                f"âœ… [{self.CHINESE_NAME}] ç”ŸæˆæˆåŠŸ",
                extra={"output_length": len(stripped), "latency_ms": round(latency_ms, 2)}
            )
            return stripped

        except Exception as e:
            logger.exception(f"ğŸ’¥ [{self.CHINESE_NAME}] generate_text å¼‚å¸¸")
            return f"ç”Ÿæˆå¤±è´¥: {str(e)}"

    @async_timed
    @retry_decorator(max_retries=3, enable_exp_backoff=True)
    async def bottom_dissolving_pronouns(
            self,
            prompt: str,
            model: str,
            params: dict
    ) -> Dict[int, str]:
        start_time = time.time()
        system_prompt = "ä½ å¿…é¡»è¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON å¯¹è±¡ã€‚ä¸è¦æœ‰ä»»ä½•é¢å¤–æ–‡å­—è§£é‡Šã€å‰ç¼€ã€åç¼€æˆ– Markdown ä»£ç å—ã€‚ç¡®ä¿è¾“å‡ºæ˜¯æœ‰æ•ˆçš„ json æ ¼å¼ã€‚"
        try:
            payload = self._build_json_payload(
                prompt=prompt,
                model=model,
                params=params,
                system_prompt=system_prompt
            )

            log_params = {k: v for k, v in params.items() if k in ("temperature", "max_tokens", "top_p")}
            logger.info(
                f"ğŸ§  [{self.CHINESE_NAME} - æŒ‡ä»£æ¶ˆè§£] è°ƒç”¨ LLM API",
                extra={
                    "model": model,
                    "params": log_params,
                    "prompt_length": len(prompt)
                }
            )

            response = await self.client.post(self.api_url, json=payload)
            latency_ms = (time.time() - start_time) * 1000

            if response.status_code != 200:
                logger.error(f"âŒ [{self.CHINESE_NAME}] æŒ‡ä»£æ¶ˆè§£ API å¤±è´¥", extra={"status": response.status_code})
                return {}

            content = self._extract_content_from_response(response.json())
            if not content:
                logger.warning(f"âš ï¸ [{self.CHINESE_NAME}] æŒ‡ä»£æ¶ˆè§£è¿”å›ç©ºå†…å®¹")
                return {}

            stripped = content.strip()
            start = stripped.find("{")
            end = stripped.rfind("}") + 1
            if start == -1 or end <= start:
                logger.warning("âš ï¸ æ— æœ‰æ•ˆ JSON", extra={"output": stripped[:200]})
                return {}

            try:
                parsed = json.loads(stripped[start:end])
            except json.JSONDecodeError:
                logger.warning("âš ï¸ JSON è§£æå¤±è´¥", extra={"output": stripped[:200]})
                return {}

            result = {}
            for k, v in parsed.items():
                if isinstance(k, str) and isinstance(v, str):
                    try:
                        idx = int(k)
                        result[idx] = v
                    except ValueError:
                        continue
            return result

        except Exception as e:
            logger.exception(f"ğŸ’¥ [{self.CHINESE_NAME}] æŒ‡ä»£æ¶ˆè§£å¼‚å¸¸")
            return {}

    @staticmethod
    def _parse_api_error(response) -> str:
        """å¯è¢«å­ç±» override ä»¥å®šåˆ¶é”™è¯¯è§£æ"""
        try:
            resp_json = response.json()
            msg = resp_json.get("error", {}).get("message") or resp_json.get("message") or ""
            code = resp_json.get("error", {}).get("type") or resp_json.get("code") or "Unknown"
            return f"[{code}] {msg}"
        except Exception:
            return f"HTTP {response.status_code} (æ— æ³•è§£æå“åº”)"

    async def close(self):
        if self.client:
            await self.client.aclose()
            self.client = None
